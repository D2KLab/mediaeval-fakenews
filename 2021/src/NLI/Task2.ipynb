{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn import metrics, preprocessing, linear_model\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMCC(y_test, y_pred):\n",
    "    value = 0\n",
    "    for y1, y2 in zip(y_test, y_pred):\n",
    "        try:\n",
    "            value += metrics.matthews_corrcoef(y1, y2)\n",
    "        except ValueError:\n",
    "            print(y1)\n",
    "            print(y2)\n",
    "            exit(1)\n",
    "    mcc = value / len(y_test)\n",
    "    return mcc\n",
    "\n",
    "def computeMCCclass(y_test, y_pred):\n",
    "    mccs = []\n",
    "    for i in range(len(y_test[0,:])):\n",
    "        mccs.append(metrics.matthews_corrcoef(y_test[:,i], y_pred[:,i]))\n",
    "    return np.mean(mccs)\n",
    "\n",
    "def one_hot_encoding(labels):\n",
    "    dictionary = {0: [1, 0,],\n",
    "                  1: [0, 1,]}\n",
    "    enc_labels = []\n",
    "    for el in labels:\n",
    "        enc_labels.append(dictionary[el])\n",
    "    return np.array(enc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/dev-full-task-2-clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'Suppressed cures',\n",
    "            1: 'Behaviour and Mind Control',\n",
    "            2: 'Antivax',\n",
    "            3: 'Fake virus',\n",
    "            4: 'Intentional Pandemic',\n",
    "            5: 'Harmful Radiation',\n",
    "            6: 'Population reduction',\n",
    "            7: 'New World Order',\n",
    "            8: 'Satanism'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {0: 'There are many (fake or) unproven medical products and methods that claim to diagnose, prevent or cure COVID-19.',\n",
    "           1: \"mind control—a broad range of tactics able to subvert an individual's control of their own thinking, behavior, emotions, or decisions. \",\n",
    "           2: 'Refusals to vaccinate, delaying vaccines, or using certain vaccines but not others. Total opposition to vaccination.',\n",
    "           3: 'Coronavirus is fake.',\n",
    "           4: 'The virus was intentionally engineered, either as a bio-weapon or to profit from the sale of vaccines. The new coronavirus had been created in a lab; one in four thought it had been engineered intentionally.',\n",
    "           5: 'Link between coronavirus disease 2019 and 5G mobile networks, claiming that the Wuhan and Diamond Princess outbreaks were directly caused by electromagnetic fields and by the introduction of 5G and wireless technologies. Conspiracy theorists have alleged that the pandemic was a cover-up for a 5G-related illness',\n",
    "           6: 'Conspiracy theorists believe that the New World Order will also be implemented through human population control to more easily monitor and control the movement of individuals. The means range from stopping the growth of human societies through reproductive health and family planning programs, which promote abstinence, contraception and abortion, or intentionally reducing the bulk of the world population through genocides by mongering unnecessary wars, through plagues by engineering emergent viruses and tainting vaccines, and through environmental disasters by controlling the weather.',\n",
    "           7: \"The New World Order (NWO) is a conspiracy theory which hypothesizes a secretly emerging totalitarian world government.The common theme in conspiracy theories about a New World Order is that a secretive power elite with a globalist agenda is conspiring to eventually rule the world through an authoritarian one-world government—which will replace sovereign nation-states—and an all-encompassing propaganda whose ideology hails the establishment of the New World Order as the culmination of history's progress\",\n",
    "           8: 'Satanism is a group of ideological and philosophical beliefs based on Satan. Satanism existed primarily as an accusation by various Christian groups toward perceived ideological opponents, rather than a self-identity.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folds = [pd.read_csv(f'../data/task2/dev-full-split-{i}.csv') for i in range(5)]\n",
    "folds = [pd.read_csv(f'../data/task2/dev-full-split-{i}.csv').ids.values for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_X = sbert.encode(data.tweet.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([0.3489, 0.4068, 0.4695, 0.4405, 0.4145])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['1', '2', '3', '4', '5', '6', '7', '8', '9']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antivax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['9'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cls_id in prompts:\n",
    "    hypothesis = prompts[cls_id]\n",
    "    hypo = sbert.encode([hypothesis])[0]\n",
    "    # print('Hypothesis: '+ hypothesis)\n",
    "\n",
    "    sim_matrix = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]\n",
    "    scores_nli = []\n",
    "\n",
    "    avg_mcc = 0\n",
    "    for k, fold in enumerate(folds):\n",
    "        train_indices = data[~data.ids.isin(fold)].index\n",
    "        test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "        Y_train, Y_test = data.iloc[train_indices][str(cls_id+1)], data.iloc[test_indices][str(cls_id+1)]\n",
    "\n",
    "        Y_prob = sim_matrix[test_indices]\n",
    "        Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "        if sum(Y_pred) > 0:\n",
    "            mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "            avg_mcc += mcc\n",
    "\n",
    "    avg_mcc /= len(folds)\n",
    "    print('MCC for', id2label[cls_id], ':', avg_mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([-0.021271192562322426, 0.0, 0.30256780576006076, 0.043507765641581195, 0.11396093644280754, 0.30149830192820465, 0.26384317819579944, 0.3024567809016109, 0.04356399614001528])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = 'Satanism is a group of ideological and philosophical beliefs based on Satan. Satanism existed primarily as an accusation by various Christian groups toward perceived ideological opponents, rather than a self-identity. '\n",
    "hypothesis = 'The Mark of the Beast, Covid vaccine?  (Revelation 13) both small and great, both rich and poor, both free and slave, to be marked on the right hand or the forehead, so that no one can buy or sell unless he has the mark, that is, the name of the beast or the number of its name.'\n",
    "hypo = sbert.encode([hypothesis])[0]\n",
    "\n",
    "satanism_tweets = data[data['9'] == 1].tweet.values\n",
    "\n",
    "sim_matrix = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nli = []\n",
    "\n",
    "best_mcc = (0, 0)\n",
    "\n",
    "for i, tweet in enumerate(satanism_tweets):\n",
    "    if i in [54, 6, 58, 72]:\n",
    "        continue\n",
    "    avg_mcc = 0\n",
    "    hypo = sbert.encode([tweet])[0]\n",
    "    sim_matrix_tweet = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]\n",
    "    \n",
    "    for k, fold in enumerate(folds):\n",
    "        train_indices = data[~data.ids.isin(fold)].index\n",
    "        test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "        Y_train, Y_test = data.iloc[train_indices]['9'], data.iloc[test_indices]['9']\n",
    "\n",
    "        Y_prob = sim_matrix_tweet[test_indices]\n",
    "        Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "        \n",
    "        mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "        avg_mcc += mcc\n",
    "        \n",
    "    avg_mcc /= 5\n",
    "    if avg_mcc > best_mcc[0]:\n",
    "        best_mcc = (avg_mcc, i)\n",
    "\n",
    "print(best_mcc, satanism_tweets[best_mcc[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_tweet = '. '.join(s[:-1] for s in satanism_tweets[[54]]) + '.'\n",
    "super_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mcc = 0\n",
    "hypo = sbert.encode([super_tweet])[0]\n",
    "sim_matrix_tweet = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]\n",
    "\n",
    "for k, fold in enumerate(folds):\n",
    "    train_indices = data[~data.ids.isin(fold)].index\n",
    "    test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "    Y_train, Y_test = data.iloc[train_indices]['9'], data.iloc[test_indices]['9']\n",
    "\n",
    "    Y_prob = sim_matrix_tweet[test_indices]\n",
    "    Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "    mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "    avg_mcc += mcc\n",
    "\n",
    "avg_mcc /= 5\n",
    "print(avg_mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New World Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = 'The New World Order is a conspiracy theory which hypothesizes a secretly emerging totalitarian world government.'\n",
    "hypo = sbert.encode([hypothesis])[0]\n",
    "\n",
    "sim_matrix = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nli = []\n",
    "\n",
    "for k, fold in enumerate(folds):\n",
    "    train_indices = data[~data.ids.isin(fold)].index\n",
    "    test_indices = data[data.ids.isin(fold)].index\n",
    "    \n",
    "    Y_train, Y_test = data.iloc[train_indices]['1'], data.iloc[test_indices]['1']\n",
    "\n",
    "    Y_prob = sim_matrix[test_indices]\n",
    "    Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "    acc = metrics.accuracy_score(Y_test, Y_pred)\n",
    "    f1s = metrics.f1_score(Y_test, Y_pred, average='weighted')\n",
    "    auc = metrics.roc_auc_score(Y_test, Y_prob, average='weighted', multi_class='ovr')\n",
    "    mcc = computeMCC(one_hot_encoding(Y_test), one_hot_encoding(Y_pred))\n",
    "    mccc = computeMCCclass(one_hot_encoding(Y_test), one_hot_encoding(Y_pred))\n",
    "    \n",
    "    scores_nli.append({'ACC':acc, 'F1':f1s, 'AUC':auc, 'MCC': mcc, 'MCCC':mccc})\n",
    "    \n",
    "    print(f'For fold {k}:', ' - '.join(f'{m}: {s:.4}' for m,s in scores_nli[-1].items()))\n",
    "\n",
    "scores_nli = pd.DataFrame(scores_nli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tweets to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mccs = {}\n",
    "for tweet_category in tqdm([str(t) for t in range(1, 10)]):\n",
    "    mccs[tweet_category] = []\n",
    "    relevant_tweets = data[data[tweet_category] == 1].tweet.values\n",
    "    for i, tweet in enumerate(relevant_tweets):\n",
    "        avg_mcc = 0\n",
    "        hypo = sbert.encode([tweet])[0]\n",
    "        sim_matrix_tweet = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]\n",
    "\n",
    "        for k, fold in enumerate(folds):\n",
    "            train_indices = data[~data.ids.isin(fold)].index\n",
    "            test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "            Y_train, Y_test = data.iloc[train_indices][tweet_category], data.iloc[test_indices][tweet_category]\n",
    "\n",
    "            Y_prob = sim_matrix_tweet[test_indices]\n",
    "            Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "            if sum(Y_pred) > 0:\n",
    "                mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "                avg_mcc += mcc\n",
    "\n",
    "        avg_mcc /= len(folds)\n",
    "        mccs[tweet_category].append((avg_mcc, i))\n",
    "\n",
    "    print('For', id2label[int(tweet_category) - 1], ': ')\n",
    "    best_mccs = sorted(mccs[tweet_category], key=lambda x: -x[0])\n",
    "    print(best_mccs[:5])\n",
    "    for supertweet_size in range(1, 2):\n",
    "        avg_mcc = 0\n",
    "        # print('MCC for supertweet_size =', supertweet_size, ': ', end='')\n",
    "        supertweet = ' and '.join(relevant_tweets[j[1]][:-1].lower() for j in best_mccs[:supertweet_size])\n",
    "        hypo = sbert.encode([supertweet])[0]\n",
    "        sim_matrix_tweet = util.pytorch_cos_sim(hypo, sbert_X).numpy()[0]\n",
    "        \n",
    "        for k, fold in enumerate(folds):\n",
    "            train_indices = data[~data.ids.isin(fold)].index\n",
    "            test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "            Y_train, Y_test = data.iloc[train_indices][tweet_category], data.iloc[test_indices][tweet_category]\n",
    "\n",
    "            Y_prob = sim_matrix_tweet[test_indices]\n",
    "            Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "            if sum(Y_test) > 0:\n",
    "                mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "                avg_mcc += mcc\n",
    "            \n",
    "        avg_mcc /= len(folds)\n",
    "        print('supertweet_size', supertweet_size, avg_mcc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid who?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_synonyms = ['itCOVID19', 'COVID19Pandemic\\n', 'CORONAVIRUS', '“SARS', 'Covids', 'COVID19\\xa0\\xa0\\xa0', \n",
    "                  'COVID21', 'Corona20', 'Covid', 'Coronavirus\\xa0', 'Covid19\\xa0\\xa0', '“Covid”', 'COVID\\n', \n",
    "                  'CoronaOutbreak\\n', 'COVID1921', 'corona', 'Covid19', 'coronavirusl\\xa0', 'Covid19\\xa0', \n",
    "                  'COVID2019', 'COVID19’', 'COVID', 'CoVid', 'wcovid', 'coronaviruses', 'CoronavirusOutbreak', \n",
    "                  'Covid19sarscov2Wuhan', 'CoronaVirus', 'covid19\\xa0', 'CovidHoax\\n', 'CoVid19', 'Corona', \n",
    "                  'COVID19fear\\xa0', 'Covid19”', '“covid”', 'COVID19\\xa0', 'COVID19\\n', 'COvid', 'CORONA', \n",
    "                  'coronavirus\\xa0', 'covid19', 'coronavirus', 'coronavirus\\xa0\\xa0', 'wCOVID', 'COVID19”', \n",
    "                  'CORONA\\xa0', 'covid1984', 'CovidHoax\\xa0', 'covid', 'Covidthis', 'Covid\\xa0', 'COVID19s', \n",
    "                  'COVID\\xa0', 'covid\\n', 'Covid19SA\\xa0', 'SARS', 'SARS\\n', 'CoVid”', 'Covid19\\n', 'COVID2019\\n',\n",
    "                  'COVID19to', 'Covid1984\\n', 'SARSCOV2', 'COVID19', 'KBFplandemicCOVID', 'SARSCOV19', \n",
    "                  'coronavirus\\n', 'Covidthey', 'Coronavirus', 'COVIDー19', 'SARSCoV2', 'CoronavirusPandemic', \n",
    "                  'distancecorona', 'Covid19TrumpsHeadUS', 'covidcoverup', 'covid\\xa0', 'covid19sk', 'COVID45', \n",
    "                  'COVID19\\xa0\\xa0', 'CoVID19', 'SARSCoV2\\n', 'postCovid19', 'coronavirus…', 'Coronaviruses', \n",
    "                  'Coronaviruslikeanger', 'Covid19”\\xa0\\xa0He', 'covid”', 'Corona5G', 'Covidby5G', \n",
    "                  'corona\\xa0\\xa0', 'Covid\\n', '“coronavirus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_covid(s):\n",
    "    tokens = s.translate(str.maketrans('', '', string.punctuation)).split(' ')\n",
    "    for i, t in enumerate(tokens):\n",
    "        if t in covid_synonyms:\n",
    "            tokens[i] = 'coronavirus'\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_covid('I hate covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_tweet'] = data['tweet'].apply(replace_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_X_new = sbert.encode(data.new_tweet.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mccs = {}\n",
    "for tweet_category in tqdm([str(t) for t in range(1, 10)]):\n",
    "    mccs[tweet_category] = []\n",
    "    relevant_tweets = data[data[tweet_category] == 1].new_tweet.values\n",
    "    for i, tweet in enumerate(relevant_tweets):\n",
    "        avg_mcc = 0\n",
    "        hypo = sbert.encode([tweet])[0]\n",
    "        sim_matrix_tweet = util.pytorch_cos_sim(hypo, sbert_X_new).numpy()[0]\n",
    "\n",
    "        for k, fold in enumerate(folds):\n",
    "            train_indices = data[~data.ids.isin(fold)].index\n",
    "            test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "            Y_train, Y_test = data.iloc[train_indices][tweet_category], data.iloc[test_indices][tweet_category]\n",
    "\n",
    "            Y_prob = sim_matrix_tweet[test_indices]\n",
    "            Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "            if sum(Y_pred) > 0:\n",
    "                mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "                avg_mcc += mcc\n",
    "\n",
    "        avg_mcc /= len(folds)\n",
    "        mccs[tweet_category].append((avg_mcc, i))\n",
    "\n",
    "    print('For', id2label[int(tweet_category) - 1], ': ')\n",
    "    best_mccs = sorted(mccs[tweet_category], key=lambda x: -x[0])\n",
    "    print(best_mccs[:5])\n",
    "    for supertweet_size in range(1, 2):\n",
    "        avg_mcc = 0\n",
    "        # print('MCC for supertweet_size =', supertweet_size, ': ', end='')\n",
    "        supertweet = ' and '.join(relevant_tweets[j[1]][:-1].lower() for j in best_mccs[:supertweet_size])\n",
    "        hypo = sbert.encode([supertweet])[0]\n",
    "        sim_matrix_tweet = util.pytorch_cos_sim(hypo, sbert_X_new).numpy()[0]\n",
    "        \n",
    "        for k, fold in enumerate(folds):\n",
    "            train_indices = data[~data.ids.isin(fold)].index\n",
    "            test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "            Y_train, Y_test = data.iloc[train_indices][tweet_category], data.iloc[test_indices][tweet_category]\n",
    "\n",
    "            Y_prob = sim_matrix_tweet[test_indices]\n",
    "            Y_pred = np.array(Y_prob >= 0.5).astype(int)\n",
    "\n",
    "            if sum(Y_test) > 0:\n",
    "                mcc = metrics.matthews_corrcoef(Y_test, Y_pred)\n",
    "                avg_mcc += mcc\n",
    "            \n",
    "        avg_mcc /= len(folds)\n",
    "        print('supertweet_size', supertweet_size, avg_mcc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "candidate_labels = list(id2label.values())\n",
    "candidate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = ['Suppressed cures', \n",
    "                    'Behaviour and Mind Control', \n",
    "                    'Antivax', \n",
    "                    'Fake virus', \n",
    "                    'Intentional Pandemic', \n",
    "                    'Harmful Radiation', \n",
    "                    'Population reduction', \n",
    "                    'New World Order', \n",
    "                    'Satanism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "thresh = 0.5\n",
    "for k, fold in tqdm(enumerate(folds)):\n",
    "    train_indices = data[~data.ids.isin(fold)].index\n",
    "    test_indices = data[data.ids.isin(fold)].index\n",
    "\n",
    "    X_train, X_test = data.tweet[train_indices], data.tweet[test_indices]\n",
    "    Y_train, Y_test = data.iloc[train_indices][[str(i) for i in range(1, 10)]], data.iloc[test_indices][[str(i) for i in range(1, 10)]]\n",
    "    \n",
    "    per_class_true = {c:[] for c in range(len(candidate_labels))}\n",
    "    per_class_pred = {c:[] for c in range(len(candidate_labels))}\n",
    "\n",
    "    for i, tweet in tqdm(enumerate(X_test), total=len(X_test)):\n",
    "        # print(i, test_indices[i], tweet)\n",
    "        # print('True label:', Y_test.values[i])\n",
    "        output = classifier(tweet, candidate_labels, multi_label=True)\n",
    "        \n",
    "        for j, s in enumerate(output['scores']):\n",
    "            per_class_true[j].append(Y_test.values[i][j])\n",
    "            per_class_pred[j].append(int(s > thresh))\n",
    "        \n",
    "    # print(per_class_true)\n",
    "    # print(per_class_pred)\n",
    "    results[k] = (per_class_true, per_class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in results:\n",
    "    avg_mcc_k = 0\n",
    "    for cls in results[k][0]:\n",
    "        avg_mcc_k += metrics.matthews_corrcoef(results[k][0][cls], results[k][1][cls])\n",
    "    \n",
    "    print('For fold', k, ', MMC =', avg_mcc_k/len(results[k][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_synonyms = ['itCOVID19', 'COVID19Pandemic\\n', 'CORONAVIRUS', '“SARS', 'Covids', 'COVID19\\xa0\\xa0\\xa0', \n",
    "                  'COVID21', 'Corona20', 'Covid', 'Coronavirus\\xa0', 'Covid19\\xa0\\xa0', '“Covid”', 'COVID\\n', \n",
    "                  'CoronaOutbreak\\n', 'COVID1921', 'corona', 'Covid19', 'coronavirusl\\xa0', 'Covid19\\xa0', \n",
    "                  'COVID2019', 'COVID19’', 'COVID', 'CoVid', 'wcovid', 'coronaviruses', 'CoronavirusOutbreak', \n",
    "                  'Covid19sarscov2Wuhan', 'CoronaVirus', 'covid19\\xa0', 'CovidHoax\\n', 'CoVid19', 'Corona', \n",
    "                  'COVID19fear\\xa0', 'Covid19”', '“covid”', 'COVID19\\xa0', 'COVID19\\n', 'COvid', 'CORONA', \n",
    "                  'coronavirus\\xa0', 'covid19', 'coronavirus', 'coronavirus\\xa0\\xa0', 'wCOVID', 'COVID19”', \n",
    "                  'CORONA\\xa0', 'covid1984', 'CovidHoax\\xa0', 'covid', 'Covidthis', 'Covid\\xa0', 'COVID19s', \n",
    "                  'COVID\\xa0', 'covid\\n', 'Covid19SA\\xa0', 'SARS', 'SARS\\n', 'CoVid”', 'Covid19\\n', 'COVID2019\\n',\n",
    "                  'COVID19to', 'Covid1984\\n', 'SARSCOV2', 'COVID19', 'KBFplandemicCOVID', 'SARSCOV19', \n",
    "                  'coronavirus\\n', 'Covidthey', 'Coronavirus', 'COVIDー19', 'SARSCoV2', 'CoronavirusPandemic', \n",
    "                  'distancecorona', 'Covid19TrumpsHeadUS', 'covidcoverup', 'covid\\xa0', 'covid19sk', 'COVID45', \n",
    "                  'COVID19\\xa0\\xa0', 'CoVID19', 'SARSCoV2\\n', 'postCovid19', 'coronavirus…', 'Coronaviruses', \n",
    "                  'Coronaviruslikeanger', 'Covid19”\\xa0\\xa0He', 'covid”', 'Corona5G', 'Covidby5G', \n",
    "                  'corona\\xa0\\xa0', 'Covid\\n', '“coronavirus']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
