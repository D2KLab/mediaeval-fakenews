{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782fabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # the GPU on robinson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358b7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertModel, AdamW, AutoTokenizer, BertForSequenceClassification, RobertaForSequenceClassification\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "conspiracies = ['Suppressed Cures',\n",
    "     'Behaviour and Mind Control',\n",
    "     'Antivax',\n",
    "     'Fake virus',\n",
    "     'Intentional Pandemic',\n",
    "     'Harmful Radiation/ Influence',\n",
    "     'Population reduction',\n",
    "     'New World Order',\n",
    "     'Satanism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bbfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'xlnet-base-cased'\n",
    "model_name = 'roberta-large'\n",
    "\n",
    "replace_lowercase_flag = False\n",
    "remove_stopwords_flag = False\n",
    "remove_hashtags_flag = True\n",
    "replace_emojis_flag = True\n",
    "clean_tweets_flag = False\n",
    "\n",
    "all_data = False\n",
    "class_weights_flag = True # always true for now\n",
    "\n",
    "classification = True\n",
    "\n",
    "# fold\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abe94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    char_to_remove = ['\\n', '\\xa0']\n",
    "    corona_synonyms = ['coronavirus',\n",
    "                      'covid-19',\n",
    "                      'covid19',\n",
    "                      'covid 19',\n",
    "                      'covid',\n",
    "                      'corona',\n",
    "                      'sarscov2'\n",
    "                      'sars',\n",
    "                      'Coronaviruses',\n",
    "                      'Coronavirus',\n",
    "                      'Corona',\n",
    "                      'Covid19',\n",
    "                      'COVID19',\n",
    "                      'Covid-19',\n",
    "                      'COVID-19',\n",
    "                      'COVID 19',\n",
    "                      'Covid',\n",
    "                      'COVID',\n",
    "                      'SARSCOV2',\n",
    "                      'SARS']\n",
    "    \n",
    "    tweets_clean = []\n",
    "    for tw in tweets:\n",
    "        for c in char_to_remove:\n",
    "            tw = tw.replace(c, '')\n",
    "        tw = tw.replace('&amp;', '&')\n",
    "        \n",
    "        for syn in corona_synonyms:\n",
    "            if syn in tw:\n",
    "                tw = tw.replace(syn, 'virus')\n",
    "        tweets_clean.append(tw)\n",
    "    return tweets_clean\n",
    "\n",
    "def extract_hashtags(tweet):\n",
    "    # Returns hashtags in a list for a given tweet\n",
    "    \n",
    "    #tweet = tweet.replace('\\xa0','')\n",
    "    #tweet = tweet.replace('\\n','')\n",
    "    \n",
    "    tweet_words = tweet.split(' ')\n",
    "    tweet_words = [w for w in tweet_words if w!='']\n",
    "    hashtags = []\n",
    "    for word in tweet_words:\n",
    "        if word[0]=='#':\n",
    "            hashtags.append(word)\n",
    "    return hashtags\n",
    "\n",
    "def extract_emojis (tw):\n",
    "    # Returns emojis in a list for a given tweet\n",
    "    # Using Deque for a sliding window (emojis can be combined together to form other emojis)\n",
    "    \n",
    "    emojis = []\n",
    "    \n",
    "    l = []\n",
    "    max_l = 7\n",
    "    \n",
    "    for i in range(0, max_l):\n",
    "        l.append(tw[-1-i])\n",
    "    l = deque(l, maxlen=max_l)\n",
    "    skip=0\n",
    "    \n",
    "    for i in range (0, len(tw)):\n",
    "        if skip == 0:\n",
    "            for j in range (max_l-1, -1, -1):\n",
    "                str_to_test = ''\n",
    "                for k in range (0, j+1):\n",
    "                    str_to_test+=l[j-k]\n",
    "                if str_to_test in emoji.UNICODE_EMOJI['en']:\n",
    "                    \n",
    "                    emojis.append(str_to_test)\n",
    "                    skip=j\n",
    "                    break\n",
    "            try:\n",
    "                l.append(tw[-1-i-max_l])\n",
    "            except IndexError:\n",
    "                l.append('')\n",
    "        else:\n",
    "            skip=skip-1\n",
    "            try:\n",
    "                l.append(tw[-1-i-max_l])\n",
    "            except IndexError:\n",
    "                l.append('')\n",
    "    emojis.reverse()\n",
    "    return emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03dccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(tweets):\n",
    "    tweets_lowercase = []\n",
    "    for tw in tweets:\n",
    "        tweets_lowercase.append(tw.lower())\n",
    "    return tweets_lowercase\n",
    "\n",
    "def remove_stopwords(tweets):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tweets_no_stopwords = []\n",
    "    for tw in tweets:\n",
    "        tw = tw.split(' ')\n",
    "        tweets_no_stopwords.append(' '.join([word for word in tw if not word in stop_words]))\n",
    "\n",
    "    return tweets_no_stopwords\n",
    "\n",
    "def remove_hashtags(tweets):\n",
    "    tweets = [tw.replace('#', '') for tw in tweets]\n",
    "    return tweets\n",
    "\n",
    "def replace_emojis(tweets):\n",
    "    tweets_no_emojis = []\n",
    "    for tw in tweets:\n",
    "        emojis = extract_emojis(tw)\n",
    "        for e in emojis:\n",
    "            e_text = emoji.UNICODE_EMOJI['en'][e].replace('_',' ').replace(':', '')\n",
    "            tw = tw.replace(e, e_text)\n",
    "        tweets_no_emojis.append(tw)\n",
    "\n",
    "    return tweets_no_emojis\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c19f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([99.5200, 20.7333, 16.2614, 13.6703, 13.5956, 47.8462, 22.4144, 24.8800,\n",
       "         45.2364], device='cuda:0'),\n",
       " tensor([[ 0.1021, 13.8222,  7.7750],\n",
       "         [ 0.1107,  1.7521,  2.5388],\n",
       "         [ 0.1140,  1.4988,  1.7771],\n",
       "         [ 0.1171,  1.7521,  1.1207],\n",
       "         [ 0.1172,  2.3923,  0.9496],\n",
       "         [ 0.1044,  4.4429,  5.1833],\n",
       "         [ 0.1098,  4.9760,  1.4465],\n",
       "         [ 0.1087,  7.7750,  1.4810],\n",
       "         [ 0.1046,  6.2200,  3.5543]], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './mediaeval-fakenews/data/task3/'\n",
    "filelist = os.listdir(data_path)\n",
    "\n",
    "\n",
    "df_list = [pd.read_csv(data_path+file) for file in filelist]\n",
    "\n",
    "\n",
    "test_df = df_list[k]    \n",
    "train_df = pd.concat(df_list[:k]+df_list[k+1:])\n",
    "\n",
    "\n",
    "tw_train = train_df['tweet'].tolist()\n",
    "tw_test = test_df['tweet'].tolist()\n",
    "ids_test = test_df['ids'].tolist()\n",
    "\n",
    "\n",
    "if all_data:\n",
    "    df = pd.read_csv('./mediaeval-fakenews/data/dev-full-task-3-clean.csv')\n",
    "    tw_train = df['tweet']\n",
    "    labels_train = df.iloc[:,1:10].values.tolist()\n",
    "\n",
    "if clean_tweets_flag:\n",
    "    tw_train = clean_tweets(tw_train)\n",
    "    tw_test = clean_tweets(tw_test)\n",
    "\n",
    "if replace_lowercase_flag:\n",
    "    tw_train = to_lowercase(tw_train)\n",
    "    tw_test = to_lowercase(tw_test)\n",
    "\n",
    "if remove_stopwords_flag:\n",
    "    tw_train = remove_stopwords(tw_train)\n",
    "    tw_test = remove_stopwords(tw_test)\n",
    "\n",
    "if remove_hashtags_flag:\n",
    "    tw_train = remove_hashtags(tw_train)\n",
    "    tw_test = remove_hashtags(tw_test)\n",
    "\n",
    "if replace_emojis_flag:\n",
    "    tw_train = replace_emojis(tw_train)\n",
    "    tw_test = replace_emojis(tw_test)\n",
    "\n",
    "\n",
    "if not all_data:\n",
    "    labels_train = train_df.iloc[:,1:10].values.tolist()\n",
    "labels_test = test_df.iloc[:,1:10].values.tolist()\n",
    "\n",
    "labels_train = [[l-1 for l in L] for L in labels_train]\n",
    "labels_test = [[l-1 for l in L] for L in labels_test]\n",
    "\n",
    "weights_tmp = [0,0,0,0,0,0,0,0,0]\n",
    "for i in range(0, 9):\n",
    "    for j in range(0, len(labels_train)):\n",
    "        if labels_train[j][i]>0:\n",
    "            weights_tmp[i]+=1\n",
    "        \n",
    "weights_inter_conspiracies = [len(labels_train)/w for w in weights_tmp]\n",
    "\n",
    "weights_inter_conspiracies = torch.FloatTensor(weights_inter_conspiracies).cuda()*2\n",
    "\n",
    "weights_intra_conspiracy = [[len(l)/l.count(j) for j in range(0, 3)] for l in [[k[i] for k in labels_train] for i in range(0, 9)]]\n",
    "weights_intra_conspiracy = torch.FloatTensor(weights_intra_conspiracy).cuda()/10\n",
    "\n",
    "#weights_inter_conspiracies = torch.clamp(weights_inter_conspiracies, min=1, max=10)\n",
    "#weights_intra_conspiracy = torch.clamp(weights_intra_conspiracy, min=1, max=10)\n",
    "weights_inter_conspiracies, weights_intra_conspiracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac5bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a72ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(tw_train)\n",
    "\n",
    "m = 0\n",
    "for tokens in tokenized_input['input_ids']:\n",
    "    if len(tokens)>m:\n",
    "        m=len(tokens)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb366dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "tokenized_input = tokenizer(tw_train, max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "tokenized_test = tokenizer(tw_test, max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "\n",
    "\n",
    "if 'roberta' in model_name:\n",
    "    train_input_ids, train_attention_mask = tokenized_input['input_ids'], tokenized_input['attention_mask']\n",
    "    test_input_ids, test_attention_mask = tokenized_test['input_ids'], tokenized_test['attention_mask']\n",
    "    \n",
    "    \n",
    "else:\n",
    "    train_input_ids, train_token_type_ids, train_attention_mask = tokenized_input['input_ids'], tokenized_input['token_type_ids'], tokenized_input['attention_mask']\n",
    "    test_input_ids, test_token_type_ids, test_attention_mask = tokenized_test['input_ids'], tokenized_test['token_type_ids'], tokenized_test['attention_mask']\n",
    "\n",
    "    train_token_type_ids = torch.tensor(train_token_type_ids)\n",
    "    test_token_type_ids = torch.tensor(test_token_type_ids)\n",
    "    \n",
    "    \n",
    "train_labels = labels_train\n",
    "test_labels = labels_test\n",
    "\n",
    "\n",
    "# Convert to torch tensor\n",
    "train_input_ids = torch.tensor(train_input_ids)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_attention_mask = torch.tensor(train_attention_mask)\n",
    "\n",
    "test_input_ids = torch.tensor(test_input_ids)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_attention_mask = torch.tensor(test_attention_mask)\n",
    "test_ids = torch.tensor(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d922f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 # 32 if 256\n",
    "\n",
    "if 'roberta' in model_name:\n",
    "    train_data = TensorDataset(train_input_ids, train_attention_mask, train_labels)\n",
    "    test_data = TensorDataset(test_input_ids, test_attention_mask, test_labels, test_ids)\n",
    "    \n",
    "else:\n",
    "    train_data = TensorDataset(train_input_ids, train_attention_mask, train_labels, train_token_type_ids)\n",
    "    test_data = TensorDataset(test_input_ids, test_attention_mask, test_labels, test_token_type_ids)\n",
    "\n",
    "    \n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812d3b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e9de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(model_name, num_labels=n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        if n_classes >1:\n",
    "            self.criterion = nn.BCELoss()\n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids, input_mask, labels):\n",
    "        outputs = self.bert(input_ids, token_type_ids, input_mask)\n",
    "        #outputs = self.classifier(outputs.pooler_output)\n",
    "        \n",
    "        logits = self.sigmoid(outputs[0])\n",
    "        \n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        \n",
    "        return loss, logits\n",
    "    \n",
    "    \n",
    "class RobertaClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.bert = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.criterions = []\n",
    "        if n_classes >1:\n",
    "            for i in range(0, 9):\n",
    "                self.criterions.append(nn.CrossEntropyLoss(weight = weights_intra_conspiracy[i]))\n",
    "            \n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "            #self.criterion = nn.BCEWithLogitsLoss()\n",
    "            \n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, input_mask, labels):\n",
    "        outputs = self.bert(input_ids, input_mask)\n",
    "        #outputs = self.classifier(outputs.pooler_output)\n",
    "        logits = outputs[0]\n",
    "        \n",
    "        if self.n_classes == 1:\n",
    "            labels=labels.float()\n",
    "            \n",
    "        losses = [0,0,0,0,0,0,0,0,0]\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        for i in range(0, 9):\n",
    "            logits_i = logits[:,3*i:3*i+3]\n",
    "            label_i = labels[:, i].long()\n",
    "            losses[i] = self.criterions[i](logits_i, label_i)\n",
    "            loss +=self.criterion(logits_i, label_i) * weights_inter_conspiracies[i]\n",
    "        loss = loss/9\n",
    "        #losses = torch.tensor(losses)\n",
    "        #loss = (losses * weights).mean()\n",
    "        \n",
    "        return loss, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28149c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaClassifier(\n",
       "  (bert): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (12): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (13): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (14): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (15): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (16): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (17): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (18): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (19): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (20): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (21): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (22): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (23): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=1024, out_features=27, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'roberta' in model_name:\n",
    "    model = RobertaClassifier(9*3)\n",
    "else:\n",
    "    if classification:\n",
    "        model = BertClassifier(9)\n",
    "    else:\n",
    "        model = BertClassifier(1)\n",
    "    \n",
    "    \n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d39099d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_grouped_parameters\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=7e-6,\n",
    "                  weight_decay = 0.001)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=4, factor=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d29ce0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_regression(val):\n",
    "    if val<0.5:\n",
    "        return 0\n",
    "    elif val<1.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3b67f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                 | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 11.318588073730469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|██                                    | 1/18 [03:32<1:00:20, 212.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 8.63825281973808\n",
      "\t Eval MCC for task 1: 0.0\n",
      "\t Eval MCCA for task 2: 0.0\n",
      "\t Eval MCCA for task 3: 0.0\n",
      "\t Eval MCCs for task 2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\t Eval MCCs for task 3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Train loss: 8.402310894012452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  11%|████▍                                   | 2/18 [07:07<57:02, 213.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 8.325041993971794\n",
      "\t Eval MCC for task 1: 0.0\n",
      "\t Eval MCCA for task 2: 0.0\n",
      "\t Eval MCCA for task 3: 0.0\n",
      "\t Eval MCCs for task 2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\t Eval MCCs for task 3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Train loss: 7.789324827194214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  17%|██████▋                                 | 3/18 [10:41<53:32, 214.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 6.803206805259951\n",
      "\t Eval MCC for task 1: 0.2447141947258015\n",
      "\t Eval MCCA for task 2: 0.15494846973112283\n",
      "\t Eval MCCA for task 3: 0.1493467697055214\n",
      "\t Eval MCCs for task 2: [0.0, 0.31039955172847616, 0.1545258786715612, 0.0, 0.0, 0.0, 0.43230226219815154, 0.4973085349819165, 0.0]\n",
      "\t Eval MCCs for task 3: [0.0, 0.25660282533063566, 0.1567213310805918, 0.0, 0.0, 0.0, 0.4330659174200893, 0.4977308535183759, 0.0]\n",
      "Train loss: 5.893232912063598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|████████▉                               | 4/18 [14:16<49:58, 214.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 5.400691055482434\n",
      "\t Eval MCC for task 1: 0.4703861764020459\n",
      "\t Eval MCCA for task 2: 0.492810532592025\n",
      "\t Eval MCCA for task 3: 0.43377216438872435\n",
      "\t Eval MCCs for task 2: [0.0, 0.7753509189623945, 0.5957502978752234, 0.0, 0.0, 0.8423786995979301, 0.8450967063808801, 0.8804506372891491, 0.49626753322264844]\n",
      "\t Eval MCCs for task 3: [0.0, 0.6575022803307398, 0.568364896092205, 0.0, 0.0, 0.6712104720433194, 0.8037275737213573, 0.8332711215311306, 0.36987313577976727]\n",
      "Train loss: 4.397790822982788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|███████████                             | 5/18 [17:50<46:24, 214.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 4.857228352177527\n",
      "\t Eval MCC for task 1: 0.5233312217643589\n",
      "\t Eval MCCA for task 2: 0.5263262705078492\n",
      "\t Eval MCCA for task 3: 0.4736392879942239\n",
      "\t Eval MCCs for task 2: [0.0, 0.7563102606028904, 0.6668103405870216, 0.0, 0.0, 0.8423786995979301, 0.8654130155601026, 0.9283852522451793, 0.677638865977519]\n",
      "\t Eval MCCs for task 3: [0.0, 0.665160962741958, 0.6617010824587476, 0.0, 0.0, 0.7571919787926702, 0.8228404865370923, 0.8810539642382431, 0.47480511717930407]\n",
      "Train loss: 3.5725017805099486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████▎                          | 6/18 [21:24<42:50, 214.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 4.260178296796737\n",
      "\t Eval MCC for task 1: 0.5272269468109094\n",
      "\t Eval MCCA for task 2: 0.6466681494502107\n",
      "\t Eval MCCA for task 3: 0.5872030394528677\n",
      "\t Eval MCCs for task 2: [0.5716805710822062, 0.7808076305249394, 0.6424042756862547, 0.27745078793191014, 0.19062005251575923, 0.9113731907929786, 0.8654130155601026, 0.9026249549802262, 0.677638865977519]\n",
      "\t Eval MCCs for task 3: [0.5733768822220587, 0.6450786554614191, 0.5996172512253415, 0.2820679729577115, 0.1919298555119832, 0.8188145672161097, 0.8228404865370923, 0.8773264828850466, 0.4737752010590464]\n",
      "Train loss: 2.9342913870811462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  39%|███████████████▌                        | 7/18 [24:58<39:13, 213.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 4.083711666445578\n",
      "\t Eval MCC for task 1: 0.5368769763429039\n",
      "\t Eval MCCA for task 2: 0.606010163412798\n",
      "\t Eval MCCA for task 3: 0.5534131235387879\n",
      "\t Eval MCCs for task 2: [0.32899004246370933, 0.7129643290909116, 0.627256733648866, 0.3372103655890851, 0.1345704502738125, 0.8423786995979301, 0.8654130155601026, 0.9276689685132454, 0.677638865977519]\n",
      "\t Eval MCCs for task 3: [0.32905103225950505, 0.5893973112587626, 0.5918260871743898, 0.34491412686225176, 0.1354951209820911, 0.7565155236680684, 0.8228404865370923, 0.8780118538741121, 0.5326665692328184]\n",
      "Train loss: 2.4309879384040833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  44%|█████████████████▊                      | 8/18 [28:31<35:37, 213.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.8173365169955837\n",
      "\t Eval MCC for task 1: 0.5933544466990065\n",
      "\t Eval MCCA for task 2: 0.6792132328213689\n",
      "\t Eval MCCA for task 3: 0.6091496743116758\n",
      "\t Eval MCCs for task 2: [0.5716805710822062, 0.7753509189623945, 0.7190281174391585, 0.5083915800692218, 0.1345704502738125, 0.8423786995979301, 0.8654130155601026, 0.9276689685132454, 0.7684367738942488]\n",
      "\t Eval MCCs for task 3: [0.4754986699484694, 0.6812713343004229, 0.7144664243637145, 0.5201254396608557, 0.1354951209820911, 0.6712104720433194, 0.8228404865370923, 0.8780118538741121, 0.5834272670950039]\n",
      "Train loss: 2.0851241607666013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|████████████████████                    | 9/18 [32:04<32:02, 213.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.662125998927701\n",
      "\t Eval MCC for task 1: 0.6246516529749481\n",
      "\t Eval MCCA for task 2: 0.714480509135917\n",
      "\t Eval MCCA for task 3: 0.6553918026113145\n",
      "\t Eval MCCs for task 2: [0.7404522814175579, 0.8158657901328759, 0.7487083726197363, 0.5472114473667538, 0.3892274283669863, 0.8423786995979301, 0.8159347278325557, 0.906074837145887, 0.6244709977429695]\n",
      "\t Eval MCCs for task 3: [0.6644426975295306, 0.7501114351619458, 0.757250758624878, 0.5250674222068544, 0.39585094137989607, 0.6722818673470029, 0.7579717079621522, 0.8832723363579132, 0.4922770569316565]\n",
      "Train loss: 1.707285927772522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  56%|█████████████████████▋                 | 10/18 [35:37<28:27, 213.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 4.161985835721416\n",
      "\t Eval MCC for task 1: 0.6306598055607447\n",
      "\t Eval MCCA for task 2: 0.7070403837109924\n",
      "\t Eval MCCA for task 3: 0.656895472691133\n",
      "\t Eval MCCs for task 2: [0.4660168636130212, 0.7687234984383388, 0.7667597135693519, 0.5652033780983937, 0.4495812690775148, 0.8423786995979301, 0.8748401621746342, 0.9522210028522291, 0.677638865977519]\n",
      "\t Eval MCCs for task 3: [0.4661032561163816, 0.703972970462803, 0.7605808110728075, 0.5534870210640622, 0.4547062739346231, 0.6722818673470029, 0.8148902992961085, 0.9525283463259038, 0.5335084086005046]\n",
      "Train loss: 1.4772813131809235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  61%|███████████████████████▊               | 11/18 [39:11<24:53, 213.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.736668371385144\n",
      "\t Eval MCC for task 1: 0.6545312689126536\n",
      "\t Eval MCCA for task 2: 0.737713195619321\n",
      "\t Eval MCCA for task 3: 0.6794569776186437\n",
      "\t Eval MCCs for task 2: [0.5716805710822062, 0.8253423467657103, 0.791134085304593, 0.5616153225027839, 0.4693822637853184, 0.9113731907929786, 0.8748401621746342, 0.9522210028522291, 0.6818298153134349]\n",
      "\t Eval MCCs for task 3: [0.5717865520445159, 0.7549789178344207, 0.7572784178126375, 0.5394944453894482, 0.47851688512507806, 0.7269066156403405, 0.8146239835010317, 0.9525283463259038, 0.5189986348944173]\n",
      "Train loss: 1.2815143013000487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████             | 12/18 [42:44<21:19, 213.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.5075118580172138\n",
      "\t Eval MCC for task 1: 0.6439095846465483\n",
      "\t Eval MCCA for task 2: 0.7156036304309641\n",
      "\t Eval MCCA for task 3: 0.6736846533524719\n",
      "\t Eval MCCs for task 2: [0.5716805710822062, 0.7446037238424782, 0.7982530894849256, 0.5465356419726813, 0.4373568052347055, 0.8423786995979301, 0.8647569087773717, 0.9530374185729434, 0.6818298153134349]\n",
      "\t Eval MCCs for task 3: [0.5717865520445159, 0.6733973180726203, 0.789685550740212, 0.5313801229608452, 0.4497528823934497, 0.7565155236680684, 0.788396467565729, 0.9533343368959807, 0.5489131258308265]\n",
      "Train loss: 1.038136663198471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  72%|████████████████████████████▏          | 13/18 [46:17<17:46, 213.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.6567366238563292\n",
      "\t Eval MCC for task 1: 0.6699532008627243\n",
      "\t Eval MCCA for task 2: 0.7169952365690079\n",
      "\t Eval MCCA for task 3: 0.6619445238272728\n",
      "\t Eval MCCs for task 2: [0.5879338712916822, 0.7753509189623945, 0.7237897237897238, 0.5472114473667538, 0.49195352211127175, 0.8423786995979301, 0.8748401621746342, 0.9276689685132454, 0.6818298153134349]\n",
      "\t Eval MCCs for task 3: [0.5121489923656456, 0.7053382939449244, 0.7179954829435102, 0.541676572205684, 0.49850294215514357, 0.6712104720433194, 0.8352295795582239, 0.9281387963603603, 0.5472595828686435]\n",
      "Train loss: 0.8913974421024322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  78%|██████████████████████████████▎        | 14/18 [49:50<14:13, 213.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.776756090502585\n",
      "\t Eval MCC for task 1: 0.6555828797211204\n",
      "\t Eval MCCA for task 2: 0.7334910488617215\n",
      "\t Eval MCCA for task 3: 0.6812730256706386\n",
      "\t Eval MCCs for task 2: [0.5716805710822062, 0.7753509189623945, 0.7734296517830072, 0.5871800927812553, 0.4848596735231358, 0.8423786995979301, 0.8812546544085976, 0.9763198672012096, 0.7089653104157574]\n",
      "\t Eval MCCs for task 3: [0.5717865520445159, 0.7053382939449244, 0.7536400653018515, 0.568014402358843, 0.48292479059797705, 0.6712104720433194, 0.803380039760358, 0.9764708306437834, 0.5986917843401752]\n",
      "Train loss: 0.7399607780575752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  83%|████████████████████████████████▌      | 15/18 [53:24<10:39, 213.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.7654970057549013\n",
      "\t Eval MCC for task 1: 0.6203962540688875\n",
      "\t Eval MCCA for task 2: 0.7250876844959753\n",
      "\t Eval MCCA for task 3: 0.6680273001504671\n",
      "\t Eval MCCs for task 2: [0.4660168636130212, 0.7687234984383388, 0.7699883013308266, 0.6297522224484765, 0.49436222956399417, 0.8423786995979301, 0.8933810322032039, 0.9522210028522291, 0.7089653104157574]\n",
      "\t Eval MCCs for task 3: [0.4661032561163816, 0.7033632881194912, 0.7378828735655217, 0.6278676856853128, 0.48925401764633525, 0.7565155236680684, 0.7694973613350685, 0.9525283463259038, 0.5092333488921208]\n",
      "Train loss: 0.6142766374349594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  89%|██████████████████████████████████▋    | 16/18 [56:57<07:06, 213.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.6072227858727977\n",
      "\t Eval MCC for task 1: 0.643946926320842\n",
      "\t Eval MCCA for task 2: 0.7471343603484901\n",
      "\t Eval MCCA for task 3: 0.6836416781073353\n",
      "\t Eval MCCs for task 2: [0.6611976106426393, 0.7982924772854063, 0.7699883013308266, 0.5594537174891406, 0.5102018772575704, 0.8423786995979301, 0.9168541746105966, 0.9530374185729434, 0.7128049663493592]\n",
      "\t Eval MCCs for task 3: [0.6613201867150081, 0.7338951526129733, 0.751288904913899, 0.5576091283991952, 0.4830440277405426, 0.6712104720433194, 0.8144715444932972, 0.9533343368959807, 0.5266013491518023]\n",
      "Train loss: 0.5618167163729668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  94%|██████████████████████████████████▉  | 17/18 [1:00:30<03:33, 213.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 4.277684109826242\n",
      "\t Eval MCC for task 1: 0.6238158157554042\n",
      "\t Eval MCCA for task 2: 0.7244550364320111\n",
      "\t Eval MCCA for task 3: 0.6656812779932406\n",
      "\t Eval MCCs for task 2: [0.4660168636130212, 0.7816688359517242, 0.7626230917630417, 0.655731331415003, 0.49247690435827945, 0.8423786995979301, 0.8885233166386386, 0.9530374185729434, 0.677638865977519]\n",
      "\t Eval MCCs for task 3: [0.4661032561163816, 0.7186186688881592, 0.7435330984425387, 0.6148790717934649, 0.47839928043553615, 0.6712104720433194, 0.8123867480909664, 0.9533343368959807, 0.5326665692328184]\n",
      "Train loss: 0.5006002197265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████| 18/18 [1:04:04<00:00, 213.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Eval loss: 3.6045175367786038\n",
      "\t Eval MCC for task 1: 0.6800975214100746\n",
      "\t Eval MCCA for task 2: 0.7686697300189133\n",
      "\t Eval MCCA for task 3: 0.7222881980038478\n",
      "\t Eval MCCs for task 2: [0.7404522814175579, 0.8158657901328759, 0.7626230917630417, 0.6342491562144837, 0.5437196036811687, 0.8423786995979301, 0.8572647548959694, 0.9530374185729434, 0.7684367738942488]\n",
      "\t Eval MCCs for task 3: [0.7405895501114731, 0.7498047405831849, 0.7435330984425387, 0.6049713266278718, 0.5232676600611006, 0.7565155236680684, 0.8185617456385034, 0.9533343368959807, 0.6100158000059086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 18\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "best_MCCA = 0\n",
    "best_F1 = 0\n",
    "best_MCCs = []\n",
    "best_MCCNC = 0\n",
    "best_loss = 999\n",
    "best_acc = 0\n",
    "best_state_dict = model.state_dict()\n",
    "best_epoch = 0\n",
    "best_MCCs = []\n",
    "best_MCCs_task2 = 0\n",
    "best_MCCA_task2 = 0\n",
    "best_MCC_task1 = 0\n",
    "\n",
    "for e in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "    # Training\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        if 'roberta' in model_name:\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "        else:    \n",
    "            b_input_ids, b_input_mask, b_labels, b_token_type_ids = batch\n",
    "            \n",
    "        if not classification:\n",
    "            b_labels = b_labels.view(-1, 1)        \n",
    "        \n",
    "        b_labels = b_labels.float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if 'roberta' in model_name:\n",
    "            outputs = model(b_input_ids, b_input_mask, b_labels)\n",
    "        else:\n",
    "            outputs = model(b_input_ids, b_token_type_ids, b_input_mask, b_labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        #print(step, loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    # Testing\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    tweets_test = []\n",
    "    \n",
    "    predictions_sep = [[], [], [], [], [], [], [], [], []]\n",
    "    predictions_task1 = []\n",
    "    \n",
    "    labels_sep = [[], [], [], [], [], [], [], [], []]\n",
    "    labels_task1 = []\n",
    "    \n",
    "    eval_loss = 0\n",
    "    steps=0\n",
    "    # Train the data for one epoch\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        if 'roberta' in model_name:\n",
    "            b_input_ids, b_input_mask, b_labels, ids = batch\n",
    "        else:    \n",
    "            b_input_ids, b_input_mask, b_labels, b_token_type_ids = batch\n",
    "            \n",
    "        if not classification:\n",
    "            b_labels = b_labels.view(-1, 1)        \n",
    "        \n",
    "        b_labels = b_labels.float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            if 'roberta' in model_name:\n",
    "                outputs = model(b_input_ids, b_input_mask, b_labels)\n",
    "            else:\n",
    "                outputs = model(b_input_ids, b_token_type_ids, b_input_mask, b_labels)\n",
    "            logits = outputs[1]\n",
    "            loss = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        ground_truth = b_labels.detach().cpu().numpy()\n",
    "        \n",
    "        steps+=1\n",
    "        eval_loss+=loss.detach().item()\n",
    "        \n",
    "        tweets_test.append(b_input_ids)\n",
    "        for i in range(0, len(logits)):\n",
    "            p = logits[i]\n",
    "            l = ground_truth[i]\n",
    "\n",
    "            predictions_task1.append(max([p[3*i: 3*i+3].argmax() for i in range(0,9)]))\n",
    "            labels_task1.append(l.max())\n",
    "            \n",
    "        for i in range(0, 9):\n",
    "            for p in logits:\n",
    "                p_i = p[3*i:3*i+3]\n",
    "                pred = np.argmax(p_i)\n",
    "                predictions_sep[i].append(pred)\n",
    "            for l in ground_truth:\n",
    "                labels_sep[i].append(l[i])\n",
    "            \n",
    "    MCCs = []\n",
    "    MCCs_task2 = []\n",
    "    for i in range(0, 9):\n",
    "        MCCs.append(metrics.matthews_corrcoef(labels_sep[i], predictions_sep[i]))\n",
    "        MCCs_task2.append(metrics.matthews_corrcoef(np.array(labels_sep[i])>0, np.array(predictions_sep[i])>0))\n",
    "\n",
    "    \n",
    "    scheduler.step(eval_loss/steps)\n",
    "    #MCCF = metrics.matthews_corrcoef(np.array(labels).flatten(), np.array(predictions).flatten())\n",
    "    #ACC = metrics.accuracy_score(labels, predictions)\n",
    "    LOSS = eval_loss/steps\n",
    "    #MCCNC = metrics.matthews_corrcoef(labels_one, predictions_one)\n",
    "    #F1 = metrics.f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    MCCA = np.mean(MCCs)\n",
    "    MCCA_task2 = np.mean(MCCs_task2)\n",
    "    MCC_task1 = metrics.matthews_corrcoef(labels_task1, predictions_task1)\n",
    "    \n",
    "    if MCCA> best_MCCA:\n",
    "        best_MCCA = MCCA\n",
    "        best_loss = LOSS\n",
    "        #best_acc = ACC\n",
    "        #best_F1 = F1\n",
    "        best_MCCs = MCCs\n",
    "        best_MCCs_task2 = MCCs_task2\n",
    "        best_MCCA_task2 = MCCA_task2\n",
    "        best_MCC_task1 = MCC_task1\n",
    "        #best_MCCNC = MCCNC\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        best_epoch = e\n",
    "    \n",
    "    print(\"\\t Eval loss: {}\".format(LOSS))\n",
    "    #print(\"\\t Eval ACC: {}\".format(ACC))\n",
    "    print(\"\\t Eval MCC for task 1: {}\".format(MCC_task1))\n",
    "    print(\"\\t Eval MCCA for task 2: {}\".format(MCCA_task2))\n",
    "    print(\"\\t Eval MCCA for task 3: {}\".format(MCCA))\n",
    "    print(\"\\t Eval MCCs for task 2: {}\".format(MCCs_task2))\n",
    "    print(\"\\t Eval MCCs for task 3: {}\".format(MCCs))\n",
    "    #print(\"\\t Eval Kappa: {}\".format(metrics.cohen_kappa_score(np.array(labels).flatten(), np.array(predictions).flatten())))\n",
    "    #print(\"\\t Eval F1 weighted: {}\".format(F1))\n",
    "    #print(\"\\t Eval F1 micro: {}\".format(metrics.f1_score(labels, predictions, average='micro')))\n",
    "    #print(\"\\t Eval F1 samples: {}\".format(metrics.f1_score(labels, predictions, average='samples')))\n",
    "    #print(\"\\t Eval F1 None: {}\".format(metrics.f1_score(labels, predictions, average=None)))\n",
    "    \n",
    "    #print([predictions.count(i) for i in range(0,3)], [labels.count(i) for i in range(0, 3)])\n",
    "    \n",
    "#torch.save(best_state_dict, './Models/task3/'+model_name+'_CV'+str(k)+'_e'+str(best_epoch)+'_'+str(round(best_MCCA, 3))+'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e5e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch  17\n",
      "\t Eval loss: 3.6045175367786038\n",
      "\t Eval MCC task 1: 0.6800975214100746\n",
      "\t Eval MCCA task 2: 0.7686697300189133\n",
      "\t Eval MCCA: 0.7222881980038478\n",
      "\t Eval MCCs for task 2: [0.7404522814175579, 0.8158657901328759, 0.7626230917630417, 0.6342491562144837, 0.5437196036811687, 0.8423786995979301, 0.8572647548959694, 0.9530374185729434, 0.7684367738942488]\n",
      "\t Eval MCCs for task 3: [0.7405895501114731, 0.7498047405831849, 0.7435330984425387, 0.6049713266278718, 0.5232676600611006, 0.7565155236680684, 0.8185617456385034, 0.9533343368959807, 0.6100158000059086]\n"
     ]
    }
   ],
   "source": [
    "print('Best epoch ', best_epoch)\n",
    "print(\"\\t Eval loss: {}\".format(best_loss))\n",
    "print(\"\\t Eval MCC task 1: {}\".format(best_MCC_task1))\n",
    "print(\"\\t Eval MCCA task 2: {}\".format(best_MCCA_task2))\n",
    "print(\"\\t Eval MCCA: {}\".format(best_MCCA))\n",
    "print(\"\\t Eval MCCs for task 2: {}\".format(best_MCCs_task2))\n",
    "print(\"\\t Eval MCCs for task 3: {}\".format(best_MCCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "648c3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), './Models/task3/'+model_name+'_full_train.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53b9a626",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/tmp/ipykernel_1689264/4057167380.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'error' is not defined"
     ]
    }
   ],
   "source": [
    "raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b33c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls Models/task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa72c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mediaeval-fakenews/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./mediaeval-fakenews/data/test-clean.csv')\n",
    "ids_test = df['ids']\n",
    "tw_test = df['tweet']\n",
    "\n",
    "if clean_tweets_flag:\n",
    "    tw_test = clean_tweets(tw_test)\n",
    "\n",
    "if replace_lowercase_flag:\n",
    "    tw_test = to_lowercase(tw_test)\n",
    "\n",
    "if remove_stopwords_flag:\n",
    "    tw_test = remove_stopwords(tw_test)\n",
    "\n",
    "if remove_hashtags_flag:\n",
    "    tw_test = remove_hashtags(tw_test)\n",
    "\n",
    "if replace_emojis_flag:\n",
    "    tw_test = replace_emojis(tw_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer(tw_test, max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "test_input_ids, test_attention_mask = tokenized_test['input_ids'], tokenized_test['attention_mask']\n",
    "\n",
    "test_labels = []\n",
    "for i in range(0, len(test_ids)):\n",
    "    test_labels.append([1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "test_input_ids = torch.tensor(test_input_ids)\n",
    "test_attention_mask = torch.tensor(test_attention_mask)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_ids = torch.tensor(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 # 32 if 256\n",
    "\n",
    "if 'roberta' in model_name:\n",
    "    test_data = TensorDataset(test_input_ids, test_attention_mask, test_labels, test_ids)\n",
    "    \n",
    "else:\n",
    "    test_data = TensorDataset(test_input_ids, test_attention_mask, test_token_type_ids)\n",
    "\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('./Models/task3/'+model_name+'_CV'+str(k)+'_e'+str(best_epoch)+'_'+str(round(best_MCCA, 3))+'.pth'))\n",
    "model.load_state_dict(torch.load('./Models/task3/roberta-large_full_train.pth'))\n",
    "model.eval()\n",
    "    \n",
    "tweets_test = []\n",
    "ids_test = []\n",
    "\n",
    "predictions = []\n",
    "predictions_sep = [[], [], [], [], [], [], [], [], []]\n",
    "\n",
    "labels = []\n",
    "labels_sep = [[], [], [], [], [], [], [], [], []]\n",
    "\n",
    "logits_test = []\n",
    "\n",
    "eval_loss = 0\n",
    "steps=0\n",
    "# Train the data for one epoch\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    if 'roberta' in model_name:\n",
    "        b_input_ids, b_input_mask, b_labels, ids = batch\n",
    "        #b_input_ids, b_input_mask, ids = batch\n",
    "    else:    \n",
    "        b_input_ids, b_input_mask, b_labels, b_token_type_ids = batch\n",
    "\n",
    "    if not classification:\n",
    "        b_labels = b_labels.view(-1, 1)        \n",
    "\n",
    "    b_labels = b_labels.float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if 'roberta' in model_name:\n",
    "            outputs = model(b_input_ids, b_input_mask, b_labels)\n",
    "        else:\n",
    "            outputs = model(b_input_ids, b_token_type_ids, b_input_mask, b_labels)\n",
    "        logits = outputs[1]\n",
    "        loss = outputs[0]\n",
    "\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    ground_truth = b_labels.detach().cpu().numpy()\n",
    "\n",
    "    steps+=1\n",
    "    eval_loss+=loss.detach().item()\n",
    "    for i in ids:\n",
    "        ids_test.append(i)\n",
    "        \n",
    "    for i in range(0, len(logits)):\n",
    "        p = logits[i]\n",
    "        logits_test.append(p)\n",
    "        predictions.append([p[3*i: 3*i+3].argmax() for i in range(0,9)])\n",
    "        \n",
    "        l = ground_truth[i]\n",
    "        labels.append(l)\n",
    "\n",
    "        predictions_task1.append(max([p[3*i: 3*i+3].argmax() for i in range(0,9)]))\n",
    "        labels_task1.append(l.max())\n",
    "\n",
    "    for i in range(0, 9):\n",
    "        for p in logits:\n",
    "            p_i = p[3*i:3*i+3]\n",
    "            pred = np.argmax(p_i)\n",
    "            predictions_sep[i].append(pred)\n",
    "        for l in ground_truth:\n",
    "            labels_sep[i].append(l[i])\n",
    "\n",
    "labels = np.array(labels).astype(int).tolist()\n",
    "MCCs = []\n",
    "MCCs_task2 = []\n",
    "for i in range(0, 9):\n",
    "    MCCs.append(metrics.matthews_corrcoef(labels_sep[i], predictions_sep[i]))\n",
    "    MCCs_task2.append(metrics.matthews_corrcoef(np.array(labels_sep[i])>0, np.array(predictions_sep[i])>0))\n",
    "\n",
    "LOSS = eval_loss/steps\n",
    "\n",
    "MCCA = np.mean(MCCs)\n",
    "MCCA_task2 = np.mean(MCCs_task2)\n",
    "MCC_task1 = metrics.matthews_corrcoef(labels_task1, predictions_task1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69897088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\t Eval loss: {}\".format(LOSS))\n",
    "print(\"\\t Eval MCC for task 1: {}\".format(MCC_task1))\n",
    "print(\"\\t Eval MCCA for task 2: {}\".format(MCCA_task2))\n",
    "print(\"\\t Eval MCCA for task 3: {}\".format(MCCA))\n",
    "print(\"\\t Eval MCCs for task 2: {}\".format(MCCs_task2))\n",
    "print(\"\\t Eval MCCs for task 3: {}\".format(MCCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['predictions'] = logits_test\n",
    "new_df['ids'] = test_ids\n",
    "#new_df.to_csv('./results/task2_cv'+str(k)+'_logits.csv', index=False)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df['ids'] = test_ids\n",
    "for i in range(0, 9):\n",
    "    new_df[conspiracies[i]] = [k[i]+1 for k in predictions]\n",
    "new_df.to_csv('./results/test_roberta-large-task-3.csv', index=False)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8278b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predictions:\n",
    "    if 1 in p and 2 in p:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tw_test)):\n",
    "    tw = tw_test[i]\n",
    "    pred = predictions[i]\n",
    "    if sum(pred)>0:\n",
    "        print(pred, tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d64b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_meaning = ['No Conspiracy', 'Discuss', 'Supports']\n",
    "tryout_sentence =\"COVID is FAKE ! It's a bioweapon to control population ! Also the Vaccine contains 5G microchips made by Bill Gates !\"\n",
    "tokenized_test = tokenizer(tryout_sentence, max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "test_input_ids, test_attention_mask = tokenized_test['input_ids'], tokenized_test['attention_mask']\n",
    "\n",
    "test_labels = []\n",
    "test_labels.append([1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "test_input_ids = torch.tensor([test_input_ids]).cuda()\n",
    "test_attention_mask = torch.tensor([test_attention_mask]).cuda()\n",
    "test_labels = torch.tensor(test_labels).cuda()\n",
    "test_ids = torch.tensor([1]).cuda()\n",
    "\n",
    "outputs = model(test_input_ids, test_attention_mask, test_labels)\n",
    "pred = np.array([outputs[1][0][3*i: 3*i+3].argmax().cpu().numpy() for i in range(0, 9)]).tolist()\n",
    "for i in range(0, 9):\n",
    "    p = pred[i]\n",
    "    if p>0:\n",
    "        print(labels_meaning[p], conspiracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eeaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
