{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f677390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # if using multiple gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f5cdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f01e39a3050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import BertModel, BertForPreTraining, AutoTokenizer\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "import emoji\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd222ce",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12fc1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 2\n",
    "# Task description can be found here https://multimediaeval.github.io/editions/2021/tasks/fakenews/\n",
    "# Models have to be downloaded here (https://mediaeval-fakenews.tools.eurecom.fr/) and put in a folder ../models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed17211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_tweets_as_list = [\n",
    "    \"This is outrageous! This politician lied about the vaccine, as it contains 5G and has been made to control population!\",\n",
    "    \"My colleague think Covid is a hoax and has been staged, how do I prove him wrong?\",\n",
    "    \"The vaccine contains the mark of the beast! It is the devil's work! Also the deep state is holding all together, the new world order is upon us\",\n",
    "    \"What about climate change? Ice is melting and temperatures keep getting warmer. I hope we find a durable solution to all this\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7427db2",
   "metadata": {},
   "source": [
    "# Some utils fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49aa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis (tw):\n",
    "    # Returns emojis in a list for a given tweet\n",
    "    # Using Deque for a sliding window (emojis can be combined together to form other emojis)\n",
    "    \n",
    "    emojis = []\n",
    "    \n",
    "    l = []\n",
    "    max_l = 7\n",
    "    \n",
    "    if len(tw)>=max_l:\n",
    "\n",
    "        for i in range(0, max_l):\n",
    "            l.append(tw[-1-i])\n",
    "        l = deque(l, maxlen=max_l)\n",
    "        skip=0\n",
    "\n",
    "        for i in range (0, len(tw)):\n",
    "            if skip == 0:\n",
    "                for j in range (max_l-1, -1, -1):\n",
    "                    str_to_test = ''\n",
    "                    for k in range (0, j+1):\n",
    "                        str_to_test+=l[j-k]\n",
    "                    if str_to_test in emoji.UNICODE_EMOJI:\n",
    "\n",
    "                        emojis.append(str_to_test)\n",
    "                        skip=j\n",
    "                        break\n",
    "                try:\n",
    "                    l.append(tw[-1-i-max_l])\n",
    "                except IndexError:\n",
    "                    l.append('')\n",
    "            else:\n",
    "                skip=skip-1\n",
    "                try:\n",
    "                    l.append(tw[-1-i-max_l])\n",
    "                except IndexError:\n",
    "                    l.append('')\n",
    "        emojis.reverse()\n",
    "    else:\n",
    "        emojis = []\n",
    "    return emojis\n",
    "\n",
    "def remove_hashtags(tweets):\n",
    "    # Remove the # char\n",
    "    \n",
    "    tweets = [tw.replace('#', '') for tw in tweets]\n",
    "    return tweets\n",
    "\n",
    "def replace_emojis(tweets):\n",
    "    # Replace emojis with their description\n",
    "    \n",
    "    tweets_no_emojis = []\n",
    "    for tw in tweets:\n",
    "        emojis = extract_emojis(tw)\n",
    "        for e in emojis:\n",
    "            e_text = emoji.UNICODE_EMOJI[e].replace('_',' ').replace(':', '')\n",
    "            tw = tw.replace(e, e_text)\n",
    "        tweets_no_emojis.append(tw)\n",
    "\n",
    "    return tweets_no_emojis\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a260d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_hashtags_flag = True\n",
    "replace_emojis_flag = True\n",
    "bw_flag = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077a39a",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa500ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_task1 = torch.tensor([0.1, 0.1, 0.1]).to(device)\n",
    "class CovidTwitterBertClassifier_task1(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.bert = BertForPreTraining.from_pretrained('digitalepidemiologylab/covid-twitter-bert-v2')    \n",
    "        self.bert.cls.seq_relationship = nn.Linear(1024, n_classes)\n",
    "        \n",
    "        if n_classes >1:\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=weights_task1)\n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids, input_mask, labels):\n",
    "        outputs = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = input_mask)\n",
    "        \n",
    "        logits = outputs[1]\n",
    "        \n",
    "        loss = self.criterion(logits, labels)\n",
    "        return loss, logits\n",
    "\n",
    "weights_task2 = torch.tensor([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]).to(device)\n",
    "class CovidTwitterBertClassifier_task2(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.bert = BertForPreTraining.from_pretrained('digitalepidemiologylab/covid-twitter-bert-v2')    \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bert.cls.seq_relationship = nn.Linear(1024, n_classes)\n",
    "        \n",
    "        if n_classes >1:\n",
    "            self.criterion = nn.BCELoss(reduction='none')\n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids, input_mask, labels):\n",
    "        outputs = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = input_mask)\n",
    "        logits = outputs[1]\n",
    "        logits = self.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        loss = (loss * weights_task2).mean()\n",
    "        \n",
    "        return loss, logits\n",
    "    \n",
    "weights_intra_conspiracy = torch.tensor([[0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1],\n",
    "                                         [0.1, 0.1, 0.1]]).to(device)\n",
    "\n",
    "class CovidTwitterBertClassifier_task3(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.bert = BertForPreTraining.from_pretrained('digitalepidemiologylab/covid-twitter-bert-v2')    \n",
    "        self.bert.cls.seq_relationship = nn.Linear(1024, n_classes)\n",
    "\n",
    "        self.criterions = []\n",
    "        for i in range(0, 9):\n",
    "            self.criterions.append(nn.CrossEntropyLoss(weight = weights_intra_conspiracy[i]))\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids, input_mask, labels):\n",
    "        outputs = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = input_mask)\n",
    "\n",
    "        logits = outputs[1]\n",
    "        \n",
    "            \n",
    "        losses = [0,0,0,0,0,0,0,0,0]\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        for i in range(0, 9):\n",
    "            logits_i = logits[:,3*i:3*i+3]\n",
    "            label_i = labels[:, i].long()\n",
    "            losses[i] = self.criterions[i](logits_i, label_i)\n",
    "            loss +=self.criterions[i](logits_i, label_i)\n",
    "        loss = loss/9\n",
    "        \n",
    "        return loss, logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1643b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK==1:\n",
    "    model = CovidTwitterBertClassifier_task1(3)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('../models/task1.pth'))\n",
    "    model.eval()\n",
    "elif TASK==2:\n",
    "    model = CovidTwitterBertClassifier_task2(9)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('../models/task2.pth'))\n",
    "    model.eval()\n",
    "elif TASK==3:\n",
    "    model = CovidTwitterBertClassifier_task3(9*3)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('../models/task3.pth'))\n",
    "    model.eval()\n",
    "else:\n",
    "    raise Exception(\"Task must be 1, 2 or 3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b200c4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = your_tweets_as_list\n",
    "if remove_hashtags_flag:\n",
    "    text = remove_hashtags(text)\n",
    "\n",
    "if replace_emojis_flag:\n",
    "    text = replace_emojis(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a43d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('digitalepidemiologylab/covid-twitter-bert')\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "tokenized_input = tokenizer(text, max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "\n",
    "input_ids, token_type_ids, attention_mask = tokenized_input['input_ids'], tokenized_input['token_type_ids'], tokenized_input['attention_mask']\n",
    "\n",
    "# labels are not important for inference\n",
    "if TASK==1:\n",
    "    labels = [1 for i in range(0, len(text))]\n",
    "elif TASK==2:\n",
    "    labels = [[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0] for i in range(0, len(text))]\n",
    "elif TASK==3:\n",
    "    labels = [[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0] for i in range(0, len(text))]\n",
    "\n",
    "\n",
    "input_ids = (torch.tensor(input_ids))\n",
    "token_type_ids = (torch.tensor(token_type_ids))\n",
    "attention_mask = (torch.tensor(attention_mask))\n",
    "labels = (torch.tensor(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a239bcb",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "425ea79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.59it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset = TensorDataset(input_ids, token_type_ids, attention_mask, labels)\n",
    "sampler = SequentialSampler(dataset)\n",
    "dataloader = DataLoader(dataset, sampler=sampler, batch_size=64)\n",
    "\n",
    "output = []\n",
    "\n",
    "for b in tqdm(dataloader):\n",
    "\n",
    "    batch = b\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    b_input_ids, b_token_type_ids, b_attention_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        logits = model(b_input_ids, b_token_type_ids, b_attention_mask, b_labels)[1]\n",
    "        if TASK==1:\n",
    "            output += logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        elif TASK==2:\n",
    "            output += (logits>0.5).int().squeeze().cpu().numpy().tolist()\n",
    "        elif TASK==3:\n",
    "            for p in logits:\n",
    "                output+=[[p[3*i: 3*i+3].argmax().item() for i in range(0,9)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deefa14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conspiracies = ['Suppressed Cures',\n",
    "     'Behaviour and Mind Control',\n",
    "     'Antivax',\n",
    "     'Fake virus',\n",
    "     'Intentional Pandemic',\n",
    "     'Harmful Radiation/ Influence',\n",
    "     'Population reduction',\n",
    "     'New World Order',\n",
    "     'Satanism']\n",
    "\n",
    "conspiracy_levels = [\"No Conspiracy\", \"Discussing\", \"Supporting\"]\n",
    "\n",
    "def pretty_print_task1(output):\n",
    "    for i in range(0, len(text)):\n",
    "        \n",
    "        t = your_tweets_as_list[i]\n",
    "        output_i = output[i]\n",
    "        \n",
    "        print(t)\n",
    "        \n",
    "        result = conspiracy_levels[output_i]\n",
    "        if output_i != 0:\n",
    "            result+=' any conspiracy theory'\n",
    "        print(\"---> \" +result)\n",
    "        print('-----'*15)\n",
    "\n",
    "def pretty_print_task2(output):\n",
    "    for i in range(0, len(text)):\n",
    "        \n",
    "        t = your_tweets_as_list[i]\n",
    "        output_i = output[i]\n",
    "        \n",
    "        print(t)\n",
    "        \n",
    "        result = ''\n",
    "        if sum(output_i) == 0:\n",
    "            result = 'No conspiracy'\n",
    "        else:\n",
    "            result+= 'Discussing or Supporting '\n",
    "            for i in range(0, 9):\n",
    "                if output_i[i]:\n",
    "                    result+=conspiracies[i]\n",
    "                    result+=', '\n",
    "                    \n",
    "            if result:\n",
    "                result = result[:-2]\n",
    "             \n",
    "        print(\"---> \" +result)\n",
    "        print('-----'*15)\n",
    "\n",
    "        \n",
    "def pretty_print_task3(output):\n",
    "    \n",
    "    for i in range(0, len(text)):\n",
    "        \n",
    "        t = text[i]\n",
    "        output_i = output[i]\n",
    "        \n",
    "        print(t)\n",
    "        \n",
    "        result = ''\n",
    "        if sum(output_i) == 0:\n",
    "            result = 'No conspiracy'\n",
    "        else:\n",
    "            for i in range(0, 9):\n",
    "                if output_i[i]:\n",
    "                    result+=', '\n",
    "                    result+=conspiracy_levels[output_i[i]]\n",
    "                    result+=' '\n",
    "                    result+=conspiracies[i]\n",
    "            if result:\n",
    "                result = result[2:]\n",
    "             \n",
    "        print(\"---> \" +result)\n",
    "        print('-----'*15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ec01a",
   "metadata": {},
   "source": [
    "# Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2955a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is outrageous! This politician lied about the vaccine, as it contains 5G and has been made to control population!\n",
      "---> Discussing or Supporting Behaviour and Mind Control, Antivax, Harmful Radiation/ Influence, Population reduction\n",
      "---------------------------------------------------------------------------\n",
      "My colleague think Covid is a hoax and has been staged, how do I prove him wrong?\n",
      "---> Discussing or Supporting Fake virus\n",
      "---------------------------------------------------------------------------\n",
      "The vaccine contains the mark of the beast! It is the devil's work! Also the deep state is holding all together, the new world order is upon us\n",
      "---> Discussing or Supporting New World Order, Satanism\n",
      "---------------------------------------------------------------------------\n",
      "What about climate change? Ice is melting and temperatures keep getting warmer. I hope we find a durable solution to all this\n",
      "---> No conspiracy\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if TASK ==1:\n",
    "    pretty_print_task1(output)\n",
    "elif TASK==2:\n",
    "    pretty_print_task2(output)\n",
    "elif TASK==3:\n",
    "    pretty_print_task3(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752be3de",
   "metadata": {},
   "source": [
    "# Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6856c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is outrageous! This politician lied about...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My colleague think Covid is a hoax and has bee...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The vaccine contains the mark of the beast! It...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What about climate change? Ice is melting and ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is outrageous! This politician lied about...   \n",
       "1  My colleague think Covid is a hoax and has bee...   \n",
       "2  The vaccine contains the mark of the beast! It...   \n",
       "3  What about climate change? Ice is melting and ...   \n",
       "\n",
       "                         label  \n",
       "0  [0, 1, 1, 0, 0, 1, 1, 0, 0]  \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 1, 1]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['text'] = your_tweets_as_list\n",
    "df['label'] = output\n",
    "#df.to_csv('./path/to/save.csv', index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b44bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
